import{_ as l,D as n,c as o,j as e,a as i,I as t,a4 as a,o as d}from"./chunks/framework.z18ruK2m.js";const W=JSON.parse('{"title":"OpenAI","description":"","frontmatter":{},"headers":[],"relativePath":"features/ai/openai.md","filePath":"features/ai/openai.md","lastUpdated":1723262227000}'),p={name:"features/ai/openai.md"},h=a('<h1 id="openai" tabindex="-1">OpenAI <a class="header-anchor" href="#openai" aria-label="Permalink to &quot;OpenAI&quot;">​</a></h1><p>Raycast Unblock provides an OpenAI feature. You can use it to generate text using the OpenAI API.</p><h2 id="usage" tabindex="-1">Usage <a class="header-anchor" href="#usage" aria-label="Permalink to &quot;Usage&quot;">​</a></h2><ol><li>Set <code>AI.default</code> to <code>openai</code> in your configuration file.</li><li>Set <code>AI.OpenAI.api_key</code> to your OpenAI API key in your configuration file.</li><li><em>(optional)</em> Set <code>AI.OpenAI.default</code> to the default model you want to use in your configuration file.</li><li><em>(optional)</em> You can add your custom models to the <code>AI.OpenAI.Models</code> in your configuration file.</li></ol><h3 id="custom-models" tabindex="-1">Custom Models <a class="header-anchor" href="#custom-models" aria-label="Permalink to &quot;Custom Models&quot;">​</a></h3><p>You can add your custom models to the <code>AI.OpenAI.Models</code> in your configuration file.</p><p>The definition of a custom model is like this:</p><div class="language-toml vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">toml</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">AI</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">OpenAI</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Models</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">model_name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span></code></pre></div><p>You shouldn&#39;t use the dot in the model name. It will be parsed as a section. For example, <code>GPT-3.5</code> should be <code>GPT3_5</code> or other names without a dot.</p><p>Other parameters you can see in the example below.</p><h2 id="configuration" tabindex="-1">Configuration <a class="header-anchor" href="#configuration" aria-label="Permalink to &quot;Configuration&quot;">​</a></h2>',11),c=e("code",null,"temperature",-1),r=e("code",null,"max_tokens",-1),k=e("li",null,[e("code",null,"api_key"),i(": Your OpenAI API key.")],-1),u=e("code",null,"default",-1),m=e("code",null,"Models",-1),y=e("code",null,"Models.<model>",-1),E=e("code",null,"base_url",-1),g=e("code",null,"api_key",-1),_=e("code",null,"real_id",-1),f=e("code",null,"provider_name",-1),b=a("<li><code>id</code>: The model id. It should be unique.</li><li><code>model</code>: The model name.</li><li><code>name</code>: The model name.</li><li><code>description</code>: The model description.</li><li><code>speed</code>: The speed of the model.</li><li><code>intelligence</code>: The intelligence of the model.</li><li><code>context</code>: The context of the model.</li>",7),F=e("code",null,"status",-1),T=e("code",null,"capabilities",-1),A=e("code",null,"image_generation",-1),C=e("code",null,"web_search",-1),x=e("code",null,"vision",-1),v=e("code",null,"Endpoints",-1),I=e("code",null,"base_url",-1),w=e("code",null,"api_key",-1),O=e("code",null,"tag",-1),B=e("code",null,"display_models",-1),P=e("em",null,[e("strong",null,"Once you set this parameter, the model list will be displayed in the order you set.")],-1),q=e("code",null,"addon_models",-1),D=e("code",null,"banned_models",-1),M=a(`<div class="tip custom-block"><p class="custom-block-title">Q: When to use the <code>Endpoints</code> parameter, and what is the difference between <code>Models</code> and <code>Endpoints</code>?</p><details class="details custom-block"><summary>Answer</summary><p>When you use the <code>Endpoints</code> parameter, you can add multiple endpoints in your configuration file, and Ray.Pro will automatically get the model list from these endpoints.</p><p>You can use the <code>display_models</code> parameter to control the displayed model list, the <code>addon_models</code> parameter to add additional models to the model list, and the <code>banned_models</code> parameter to ban the displayed models.</p><p>Also, Ray.Pro will automatically match the model information based on the Model ID, so you don&#39;t need to add the model information to the configuration file.</p><p>When you use the <code>Models</code> parameter, you need to manually add the model information to the configuration file. This is suitable for when you only need to use a single model.</p></details></div><div class="tip custom-block"><p class="custom-block-title">Tips: When to use the <code>base_url</code> parameter?</p><p>You can use the <code>base_url</code> parameter when you want to use a different base URL for the model. For example, you can use it to use a different endpoint for the model.</p><p>Also, <code>api_key</code> and <code>real_id</code> parameters are used for the same purpose. You can use them when you want to use a different API key or real id for the model.</p><p><code>real_id</code> is the real id of the model. It&#39;s used to request the model from the api. If you don&#39;t provide it, the <code>id</code> parameter will be used as the real id.</p><details class="details custom-block"><summary>Example for <code>real_id</code>, <code>api_key</code>, and <code>base_url</code></summary><ul><li>Model1 <ul><li>id: <code>something-endpoint-gpt-4-0125-preview</code></li><li>real_id: <code>gpt-4-0125-preview</code></li><li>base_url: <code>https://something-endpoint.com/v1</code></li><li>Actually, the request will be sent to <code>https://something-endpoint.com/v1/chat/completions</code>, and model id will be <code>gpt-4-0125-preview</code>.</li></ul></li><li>Model2 <ul><li>id: <code>another-endpoint-gpt-4-0125-preview</code></li><li>real_id: <code>gpt-4-0125-preview</code></li><li>base_url: <code>https://another-endpoint.com/v1</code></li><li>Actually, the request will be sent to <code>https://another-endpoint.com/v1/chat/completions</code>, and model id will be <code>gpt-4-0125-preview</code>.</li></ul></li></ul></details></div><h3 id="example" tabindex="-1">Example <a class="header-anchor" href="#example" aria-label="Permalink to &quot;Example&quot;">​</a></h3><div class="language-toml vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">toml</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">AI</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">OpenAI</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">api_key = </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;&lt;your api key&gt;&#39;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">default = </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># temperature = 0.5</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># max_tokens = 100</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">AI</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">OpenAI</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Models</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">GPT4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">id = </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;gpt-4-0125-preview&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model = </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;gpt-4-0125-preview&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">name = </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;GPT-4 (Preview)&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">description = </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;GPT-4 is OpenAI’s most capable model with broad general knowledge, allowing it to follow complex instructions and solve difficult problems.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">speed = </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">intelligence = </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">context = </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">8</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">status = </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;beta&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">AI</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">OpenAI</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Models</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">GPT4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Capabilities</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">image_generation = </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;dall-e-2&quot;</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> # Write generation model.</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">web_search = </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">true</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> # The premise is that the model needs to support Function Call. Or if the model defaults to having network access and cannot be turned off, you need to set this parameter to fixed.</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">vision = </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">true</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> # The model needs to support vision capability.</span></span></code></pre></div>`,4);function S(N,V,R,Y,U,G){const s=n("Badge");return d(),o("div",null,[h,e("ul",null,[e("li",null,[c,i(": The temperature of the model. "),t(s,{type:"info",text:"Optional"})]),e("li",null,[r,i(": The maximum tokens of the model. "),t(s,{type:"info",text:"Optional"})]),k,e("li",null,[u,i(": The default model to use. "),t(s,{type:"info",text:"Optional"})]),e("li",null,[m,i(": The custom models to use. "),t(s,{type:"info",text:"Optional"}),e("ul",null,[e("li",null,[y,i(": The model name. "),e("ul",null,[e("li",null,[E,i(": The base URL of the model. "),t(s,{type:"info",text:"Optional"}),i(),t(s,{type:"warning",text:"^v0.5.0-beta.2"})]),e("li",null,[g,i(": The API key of the model. "),t(s,{type:"info",text:"Optional"}),i(),t(s,{type:"warning",text:"^v0.5.0-beta.2"})]),e("li",null,[_,i(": The real id of the model. "),t(s,{type:"info",text:"Optional"}),i(),t(s,{type:"warning",text:"^v0.5.0-beta.2"})]),e("li",null,[f,i(": The provider name of the model. "),t(s,{type:"info",text:"Optional"}),i(),t(s,{type:"warning",text:"^v0.5.0-beta.2"})]),b,e("li",null,[F,i(": The status of the model. "),t(s,{type:"info",text:"Optional"})]),e("li",null,[T,i(": The capabilities of the model. "),t(s,{type:"info",text:"Optional"}),e("ul",null,[e("li",null,[A,i(": The image generation capability. (Need DALL supported) "),t(s,{type:"info",text:"Optional"})]),e("li",null,[C,i(": The web search capability. (Function Call) "),t(s,{type:"info",text:"Optional"})]),e("li",null,[x,i(": The vision capability. (Need model supported) "),t(s,{type:"info",text:"Optional"})])])])])])])]),e("li",null,[v,i(": Custom endpoints "),t(s,{type:"info",text:"Optional"}),i(),t(s,{type:"warning",text:"^v0.7.0-beta.1"}),e("ul",null,[e("li",null,[I,i(": The base URL of the endpoint. "),t(s,{type:"info",text:"Optional"})]),e("li",null,[w,i(": The API key of the endpoint. "),t(s,{type:"info",text:"Optional"})]),e("li",null,[O,i(": The tag of the endpoint. It will be displayed in the model list. "),t(s,{type:"info",text:"Optional"})]),e("li",null,[B,i(": The models to display in the model list. "),P,i(),t(s,{type:"info",text:"Optional"})]),e("li",null,[q,i(": The models to add to the model list. "),t(s,{type:"info",text:"Optional"})]),e("li",null,[D,i(": The models to ban from the model list. "),t(s,{type:"info",text:"Optional"})])])])]),M])}const $=l(p,[["render",S]]);export{W as __pageData,$ as default};
